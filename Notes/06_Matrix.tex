\include{includes}
%SetFonts


\title{Topic 6: Matrices}
\author{02-680: Essentials of Mathematics and Statistics}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

%%%%%
You can almost think of a \emph{matrix} as a 2-dimension vector. 
We say that an ``$n$-by-$m$'' matrix $M \in \reals^{n\times m}$ has $n$ rows and $m$ columns and we usually write it as:
\[
M = \left[\begin{matrix}
M_{1,1}& 	M_{1,2}& 	\dots& M_{1,m}\\
M_{2,1}& 	M_{2,2}& 	\dots& M_{2,m}\\ 
\vdots & \vdots & \ddots & \vdots \\ 
M_{n,1}& 	M_{n,2}& 	\dots& M_{n,m}
\end{matrix}\right]
\]



%%%%%%%%%
\section{Simple Matrix Operations}

\subsection{Addition and Scalar Multiplication.}
Like with vectors, addition of two matrices as well as scalar multiplication are element-wise operations, so for matrices $M,N \in \reals^{n\times m}$ and scalar $a\in\reals$:
\[O = M+N \rightarrow O_{i,j} = M_{i,j} + N_{i,j} \;\; \forall 1 \le i \le n, 1 \le j \le m\]
\[O = aM \rightarrow O_{i,j} = a M_{i,j} \;\; \forall 1 \le i \le n, 1 \le j \le m\]

\subsection{Transpose} 
For a given matrix $M \in \reals^{n\times m}$, the transpose $M^T \in \reals^{m \times n}$ is defined such that:
\[
\forall I\in[0,n-1], j\in[0,m-1] : M^T_{j,i} = M_{i,j} 
\]
This operation works for both matrixes and vectors (which are really $n\times1$ matrices).
Some examples: 
\begin{center}
$\left[\begin{matrix}
1 & 2 & 3\\
4 & 5 & 6
\end{matrix}\right]^T = 
\left[\begin{matrix}
1 & 4 \\
2 & 5 \\
3 & 6
\end{matrix}\right]$%
\hspace{5em}
$\left[\begin{matrix}
7 \\
8 \\
9 \\
10 \\
\end{matrix}\right]^T = \left[\begin{matrix}
7 & 8 & 9 & 10
\end{matrix}\right]
$
\end{center}
%%%%%%%%%
\section{Matrix Multiplication}
Just like with vectors, multiplying two matrices is more complicated than scalars. 
The first question is the size of the result, if we multiply $C \in \reals^{n\times p}$ with $D \in \reals^{p\times m}$ we get a matrix $E \in \reals^{n\times m}$;
notice that the \textit{inner} dimensions are the same.
And the values in $E$ are defined as follows:
\[
E_{i,j} = \sum_{k=1}^m C_{i,k}D{k,j}
\]

We can actually rewrite this using dot product, but lets quickly introduce some notation.
Lets first say for a matrix $A\in\reals^{n\times m}$ we could say that 
\[A = A_{[n],[m]}\] 
remember here that $[n] \iff [1,n] \iff \{1,2,...,n\}$. 
So really the equation above redefines $A$ using a list of columns and a list of rows. 
That means we can lets $C_{i,[p]}$ is the $i$-th column of $C$, and $D_{[p],j}$ is the $j$-th column of $D$.
In that case \[E_{i,j} = C_{i,[p]}\cdot D_{[p],j}^T.\]

What can we do with it? Lets define the following:
\begin{itemize}
\item $G$ is an $n$-by-$m$ matrix where $G_{i,j}=1$ if actor $i$ was in an episode of the show $j$ (and $0$ otherwise)
\item $H$ be an $m$-by-$p$ matrix where $H_{j,k}=1$ if the show $j$ is available to stream on service $k$ (and $0$ otherwise) 
\end{itemize}


%%%%%%%%%%
\section{Square Matrices}
Square matrices (that is, matrices where $m=n$) come up a lot, 
possibly because of this or vice versa there are several properties and operations that exist only on these. 

In a square matrix $N\in\reals^{n\times n}$, we define the \emph{main diagonal} as the entries where the horizontal and vertical component are equal; 
i.e. $\left\{N_{i,i} \mid 1 \le i \le n\right\}$. 

\paragraph{Symmetry.}
We say a square matrix is \emph{symmetric} if $A=A^T$
(and \textit{anti-symmetric} is $A = -A^T$). 
That is, $A$ is symmetric if it is mirrored across the main diagonal which often happens for things like distance matrices (though not always as we'll see). 
Similarly, it is anti-symmetric if it's mirrored across the \textit{anti-diagonal}.

\paragraph{Trace. }
The \emph{trace} of a matrix $tr(A)$ is the sum of the diagonal elements: \[tr(A) := \sum_{I=1}^n A_{i,i}.\] 
The trace does not change under transpose, and is distributive across sum and scalar product. 

\subsection{Identity Matrix}

The \emph{identity} matrix $I_n \in\reals^{n\times n}$ (sometimes simplified to just $I$ when the size is implied from context) 
is a special symmetric matrix where the main diagonal values are $1$ and all other values are $0$.
\[
\forall I,j \in [1,n]: I_{i,j} = \begin{cases} 1 & i=j\\ 0 & i\ne j\end{cases}
\]
Note, $I_n$ is symmetric and $tr(I_n)=n$.

Note also that for any matrix $A\in\reals^{n\times m}$ 
\[
AI_m = A \;\;\;\textnormal{and}\;\;\; I_nA = A.
\]


\subsection{Determinants}
We define the \emph{determinant} of a square matrix $det: \reals^{n\times n} \mapsto \reals$ 
as a function with the range of all square matrices and a codomain of real numbers. 
We often write this as $|A|$ for $A\in\reals^{n\times n}$. 

We define determinant \emph{recursively} (meaning it is a function makes a reference to itself), 
but we first need to define a method for constructing sub-matrices. 

Using the notation of sets of column/row indexes ($A = A_{[n],[n]}$) can then use set math to manipulate those rows/columns (mainly using $\setminus$): 
\[A_{[n]\setminus i,[n]\setminus j}.\]
Which is A with all but row $i$ and all but column $j$. 

For instance: 
\[A = \left[\begin{matrix}A_{11} & A_{12} & A_{13}\\ A_{21} & A_{22} & A_{23}\\ A_{31} & A_{32} & A_{33}\\\end{matrix}\right] \;\;\;\;\;\;\;\;
A_{[3]\setminus 2,[3]} = \left[\begin{matrix}A_{11} & A_{12} & A_{13}\\ A_{31} & A_{32} & A_{33}\\\end{matrix}\right]\]

To make this easier we will actually shorten this to: 
\[A_{[n]\setminus i,[n]\setminus j} \iff A_{\setminus i,\setminus j}.\]

We need that notation to more easily define the determinate for any chosen $j$:
\[
|A| := (-1)^{(i+j)} \sum_{i=1}^n A_{ij} \left|A_{\setminus i,\setminus j}\right|.
\]
(It can also be defined for a fixed $i$ and sum over $i$.)

Some explicit examples:
\[\left|\left[A_{11}\right]\right| = A_{11}\]
\[\left|\left[\begin{matrix}A_{11} & A_{12}\\ A_{21} & A_{22}\\\end{matrix}\right]\right| = A_{11}A_{22}-A_{21}A_{21}\]
\[\left|\left[\begin{matrix}A_{11} & A_{12} & A_{13}\\ A_{21} & A_{22} & A_{23}\\ A_{31} & A_{32} & A_{33}\\\end{matrix}\right]\right| = A_{11}\left|\left[\begin{matrix}A_{22} & A_{23}\\ A_{32} & A_{33}\\\end{matrix}\right]\right|-A_{12}\left|\left[\begin{matrix}A_{21} & A_{23}\\ A_{31} & A_{33}\\\end{matrix}\right]\right|+A_{13}\left|\left[\begin{matrix}A_{21} & A_{22}\\ A_{31} & A_{32}\\\end{matrix}\right]\right|\]


\section*{Useful References}
Liben-Nowell, ``Connecting Discrete Mathematics and Computer Science, 2e''. \S 2.4\\
Wilder, ``10-606-f23:Lecture 3'' GitHub repository, \url{https://github.com/bwilder0/10606-f23/blob/main/files/notes_linalg.pdf}\\
Kolter, ``Linear Algebra Review and Reference'', \url{https://www.cs.cmu.edu/~zkolter/course/15-884/linalg-review.pdf} \S1.1,2.3,3.1-3.5

\end{document}